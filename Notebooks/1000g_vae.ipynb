{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Train VAE on dietnet data\n",
    "\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import os\n",
    "import h5py\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sys.path.append(\"/mnt/wd_4tb/shared_disk_wd4tb/mattscicluna/DIETNETWORK/\")\n",
    "sys.path.append(\"/mnt/wd_4tb/shared_disk_wd4tb/mattscicluna/DIETNETWORK/Dietnet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Dietnet.make_attributions import load_data, load_model\n",
    "from Dietnet.helpers import dataset_utils as du\n",
    "from Dietnet.helpers import model as model\n",
    "from Dietnet.Interpretability import attribution_manager as am\n",
    "from Dietnet.helpers import mainloop_utils as mlu\n",
    "from Dietnet.helpers import log_utils as lu\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1,2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 23\n",
    "which_fold = 0\n",
    "seed = 23\n",
    "train_valid_ratio = 0.75\n",
    "batch_size = 12\n",
    "\n",
    "exp_path = Path('/home/rochefortc/shared_disk_wd4tb/rochefortc/Dietnetwork/Dietnet2/1000G_EXP/EXP01_2020.07')\n",
    "exp_folder = 'REPRODUCE_2020.07'\n",
    "full_path = exp_path / exp_folder / '{}_fold{}'.format(exp_folder, which_fold)\n",
    "model_path =  full_path / 'model_params.pt'\n",
    "\n",
    "dataset = 'dataset.npz'\n",
    "embedding = 'embedding.npz'\n",
    "folds_indexes = 'folds_indexes.npz'\n",
    "\n",
    "# Set GPU\n",
    "print('Cuda available:', torch.cuda.is_available())\n",
    "print('Current cuda device ', torch.cuda.current_device())\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print('device:', device)\n",
    "\n",
    "# Fix seed\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "if device.type=='cuda':\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "print('Seed:', str(seed))\n",
    "\n",
    "# Get fold data (indexes and samples are np arrays, x,y are tensors)\n",
    "data = du.load_data(os.path.join(exp_path, dataset))\n",
    "folds_indexes = du.load_folds_indexes(\n",
    "        os.path.join(exp_path, folds_indexes))\n",
    "(train_indexes, valid_indexes, test_indexes,\n",
    " x_train, y_train, samples_train,\n",
    " x_valid, y_valid, samples_valid,\n",
    " x_test, y_test, samples_test) = du.get_fold_data(which_fold,\n",
    "                                                  folds_indexes,\n",
    "                                                  data,\n",
    "                                                  split_ratio=train_valid_ratio,\n",
    "                                                  seed=seed)\n",
    "\n",
    "# Put data on GPU\n",
    "x_train, x_valid, x_test = x_train.float(), x_valid.float(), x_test.float()\n",
    "\n",
    "# Compute mean and sd of training set for normalization\n",
    "mus, sigmas = du.compute_norm_values(x_train)\n",
    "\n",
    "# Replace missing values\n",
    "du.replace_missing_values(x_train, mus)\n",
    "du.replace_missing_values(x_valid, mus)\n",
    "du.replace_missing_values(x_test, mus)\n",
    "\n",
    "# Normalize\n",
    "x_train_normed = du.normalize(x_train, mus, sigmas)\n",
    "x_valid_normed = du.normalize(x_valid, mus, sigmas)\n",
    "x_test_normed = du.normalize(x_test, mus, sigmas)\n",
    "\n",
    "class FoldDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, xs, xs_unnormed, ys, samples):\n",
    "        self.xs = xs #tensor on gpu\n",
    "        self.xs_unnormed = xs_unnormed\n",
    "        self.ys = ys #tensor on gpu\n",
    "        self.samples = samples #np array\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # Index can be a number or a list of numbers\n",
    "        x = self.xs[index]\n",
    "        xun = self.xs_unnormed[index]\n",
    "        y = self.ys[index]\n",
    "        sample = self.samples[index]\n",
    "\n",
    "        return x, xun, y, sample\n",
    "\n",
    "# Make fold final dataset\n",
    "train_set = FoldDataset(x_train_normed, x_train, y_train, samples_train)\n",
    "valid_set = FoldDataset(x_valid_normed, x_valid, y_valid, samples_valid)\n",
    "test_set = FoldDataset(x_test_normed, x_test, y_test, samples_test)\n",
    "\n",
    "# Load embedding\n",
    "emb = du.load_embedding(os.path.join(exp_path, embedding), which_fold)\n",
    "emb = emb.to(device)\n",
    "emb = emb.float()\n",
    "\n",
    "# Normalize embedding\n",
    "emb_norm = (emb ** 2).sum(0) ** 0.5\n",
    "emb = emb/emb_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate model\n",
    "# Input size\n",
    "n_feats_emb = emb.size()[1] # input of aux net\n",
    "n_feats = emb.size()[0] # input of main net\n",
    "\n",
    "# Hidden layers size\n",
    "emb_n_hidden_u = 512\n",
    "\n",
    "#  latent space size\n",
    "hidden_dim = 100\n",
    "\n",
    "input_dropout = 0\n",
    "\n",
    "# Output layer\n",
    "n_targets = max(torch.max(train_set.ys).item(),\n",
    "                torch.max(valid_set.ys).item(),\n",
    "                torch.max(test_set.ys).item()) + 1 #0-based encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class encoder(nn.Module):\n",
    "    def __init__(self, n_feats, n_hidden1_u, latent_dim, \n",
    "                 input_dropout=0., eps=1e-5, incl_bias=True):\n",
    "        super(encoder, self).__init__()\n",
    "\n",
    "        # Dropout on input layer\n",
    "        self.input_dropout = nn.Dropout(p=input_dropout)\n",
    "\n",
    "        self.bn = nn.BatchNorm1d(num_features=n_hidden1_u, eps=eps)\n",
    "\n",
    "        # 2nd hidden layer\n",
    "        self.fc = nn.Linear(n_hidden1_u, n_hidden1_u//2)\n",
    "        self.bn2 = nn.BatchNorm1d(num_features=n_hidden1_u//2, eps=eps)\n",
    "        \n",
    "        self.mean_fc = nn.Linear(n_hidden1_u//2, latent_dim)\n",
    "        self.logvar_fc = nn.Linear(n_hidden1_u//2, latent_dim)\n",
    "        nn.init.xavier_uniform_(self.mean_fc.weight)\n",
    "        nn.init.xavier_uniform_(self.logvar_fc.weight)\n",
    "        nn.init.zeros_(self.mean_fc.bias)\n",
    "        nn.init.zeros_(self.logvar_fc.bias)\n",
    "\n",
    "        #  bias term for fat layer\n",
    "        if incl_bias:\n",
    "            self.fat_bias = nn.Parameter(data=torch.rand(n_hidden1_u), requires_grad=True)\n",
    "            nn.init.zeros_(self.fat_bias)\n",
    "        else:\n",
    "            self.fat_bias = None\n",
    "\n",
    "        # Dropout\n",
    "        self.dropout = nn.Dropout()\n",
    "\n",
    "\n",
    "    def forward(self, x, fatLayer_weights):\n",
    "        # input size: batch_size x n_feats\n",
    "        # weight = comes from feat embedding net\n",
    "        # now ^^^ is passed with forward\n",
    "        x = self.input_dropout(x)\n",
    "\n",
    "        z = F.linear(x, fatLayer_weights, bias=self.fat_bias)\n",
    "        a = torch.relu(z)\n",
    "        a = self.bn(a)\n",
    "        a = self.dropout(a)\n",
    "        \n",
    "        z = self.fc(a)\n",
    "        a = torch.relu(z)\n",
    "        a = self.bn2(a)\n",
    "\n",
    "        mu = self.mean_fc(a)\n",
    "        logvar = self.logvar_fc(a)\n",
    "\n",
    "        return mu, logvar\n",
    "\n",
    "\n",
    "class decoder(nn.Module):\n",
    "    def __init__(self, num_inputs, n_hidden1_u, latent_dim, eps=1e-5, incl_bias=True):\n",
    "        super(decoder, self).__init__()\n",
    "\n",
    "        self.fc = nn.Linear(latent_dim, n_hidden1_u//2)\n",
    "        self.bn = nn.BatchNorm1d(num_features=n_hidden1_u//2, eps=eps)\n",
    "        self.fc2 = nn.Linear(n_hidden1_u//2, n_hidden1_u)\n",
    "        self.bn2 = nn.BatchNorm1d(num_features=n_hidden1_u, eps=eps)\n",
    "\n",
    "        #  bias term for fat layer\n",
    "        if incl_bias:\n",
    "            self.fat_bias = nn.Parameter(data=torch.rand(num_inputs), requires_grad=True)\n",
    "            nn.init.zeros_(self.fat_bias)\n",
    "        else:\n",
    "            self.fat_bias = None\n",
    "\n",
    "        self.bn3 = nn.BatchNorm1d(num_features=num_inputs, eps=eps)\n",
    "\n",
    "    def forward(self, x, fatLayer_weights):\n",
    "        z = self.fc(x)\n",
    "        a = torch.relu(z)\n",
    "        a = self.bn(a)\n",
    "\n",
    "        z = self.fc2(a)\n",
    "        a = torch.relu(z)\n",
    "        a = self.bn2(a)\n",
    "\n",
    "        x_hat = F.linear(a, fatLayer_weights, bias=self.fat_bias)\n",
    "        x_hat = torch.relu(x_hat)\n",
    "        x_hat = self.bn3(x_hat)\n",
    "\n",
    "        return torch.sigmoid(x_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE(nn.Module):\n",
    "    def __init__(self, num_inputs, n_feats, n_hidden_u, param_init, latent_dim, input_dropout=0., eps=1e-5, incl_bias=True):\n",
    "        super(VAE, self).__init__()\n",
    "        self.feat_emb_enc = model.Feat_emb_net(n_feats, n_hidden_u, param_init)\n",
    "        self.feat_emb_dec = model.Feat_emb_net(n_feats, n_hidden_u, param_init)\n",
    "        self.encoder = encoder(n_feats, n_hidden_u, latent_dim, input_dropout, eps, incl_bias)\n",
    "        self.decoder = decoder(num_inputs, n_hidden_u, latent_dim, eps, incl_bias)\n",
    "\n",
    "    def reparameterize(self, mu, logvar):\n",
    "        std = torch.exp(0.5*logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + eps*std\n",
    "\n",
    "    def forward(self, emb, x_batch):\n",
    "\n",
    "        # Forward pass in auxilliary net\n",
    "        fatLayer_weights_enc = self.feat_emb_enc(emb)\n",
    "\n",
    "        #  if we are in dataparallel mode, we add extra dim during dataloading and remove it here\n",
    "        if len(fatLayer_weights_enc.shape) > 2:\n",
    "            fatLayer_weights_enc = fatLayer_weights_enc[0]\n",
    "        fatLayer_weights_enc = torch.transpose(fatLayer_weights_enc, 1, 0)\n",
    "\n",
    "        fatLayer_weights_dec = self.feat_emb_dec(emb)\n",
    "        if len(fatLayer_weights_dec.shape) > 2:\n",
    "            fatLayer_weights_dec = fatLayer_weights_dec[0]\n",
    "\n",
    "        mu, logvar = self.encoder(x_batch, fatLayer_weights_enc)\n",
    "\n",
    "        # Reparameterize\n",
    "        z = self.reparameterize(mu, logvar)\n",
    "\n",
    "        # Forward pass in decoder net\n",
    "        dec_params = self.decoder(z, fatLayer_weights_dec)\n",
    "\n",
    "        return dec_params, mu, logvar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vae = VAE(n_feats, n_feats_emb, emb_n_hidden_u, None, hidden_dim)\n",
    "vae = nn.DataParallel(vae)\n",
    "vae = vae.to(device)\n",
    "\n",
    "print('\\n***Nb features in models***')\n",
    "print('n_feats_emb:', n_feats_emb)\n",
    "print('n_feats:', n_feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reconstruction + KL divergence losses summed over all elements and batch\n",
    "def loss_function(dec_params, x, mu, logvar):\n",
    "\n",
    "    # Compute -logP(x|z) where we model x~binomial(n=2, p=dec_params)\n",
    "    BCE = - torch.cat([(1-dec_params[x == 0])**2, \n",
    "                       (dec_params[x == 1])*(1-(dec_params[x == 1])),\n",
    "                       (dec_params[x == 2])**2]).log().sum()\n",
    "\n",
    "    # see Appendix B from VAE paper:\n",
    "    # Kingma and Welling. Auto-Encoding Variational Bayes. ICLR, 2014\n",
    "    # https://arxiv.org/abs/1312.6114\n",
    "    # 0.5 * sum(1 + log(sigma^2) - mu^2 - sigma^2)\n",
    "    KLD = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "\n",
    "    return BCE + KLD, BCE, KLD\n",
    "\n",
    "\n",
    "# Loss\n",
    "criterion = loss_function\n",
    "\n",
    "# Optimizer\n",
    "lr = 1e-2\n",
    "optimizer = torch.optim.Adam(vae.parameters(), lr=lr)\n",
    "\n",
    "# Training loop hyper param\n",
    "n_epochs = 50\n",
    "batch_size = 138\n",
    "\n",
    "# Minibatch generators\n",
    "train_generator = DataLoader(train_set, batch_size=batch_size)\n",
    "valid_generator = DataLoader(valid_set,\n",
    "                             batch_size=batch_size,\n",
    "                             shuffle=False)\n",
    "test_generator = DataLoader(test_set,\n",
    "                            batch_size=batch_size,\n",
    "                            shuffle=False)\n",
    "\n",
    "#  prepare for dataparallel mode (by duplicating along 0th dimension, so each GPU gets a copy!)\n",
    "emb = emb.unsqueeze(0).repeat(repeats=(2,1,1)).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = []\n",
    "bces = []\n",
    "klds = []\n",
    "\n",
    "for e in range(n_epochs):\n",
    "    for x_batch, x_batch_unnormed, _, _ in train_generator:\n",
    "        vae = vae.train()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        dec_params, mu, logvar = vae(emb, x_batch.to(device))\n",
    "\n",
    "        #  sample from decoder posterior (binomial with support [0,1,2])\n",
    "        #dec_dist = torch.distributions.binomial.Binomial(total_count=2, probs=dec_params)\n",
    "        #out_sample = dec_dist.sample()\n",
    "\n",
    "        # Compute loss\n",
    "        loss, bce, kld = criterion(dec_params, x_batch_unnormed, mu, logvar)\n",
    "\n",
    "        # Compute gradients in discrim net\n",
    "        loss.backward()\n",
    "\n",
    "        # Optim\n",
    "        optimizer.step()\n",
    "\n",
    "        # Monitoring: Minibatch\n",
    "        losses.append(loss.item())\n",
    "        bces.append(bce.item())\n",
    "        klds.append(kld.item())\n",
    "        print('[{}/{}] loss: {:.3f} bce: {:.3f} kld: {:.3f}'.format(len(losses)%len(train_generator), \n",
    "                                                                    len(train_generator), \n",
    "                                                                    loss.item(), \n",
    "                                                                    bce.item(),\n",
    "                                                                    kld.item()))\n",
    "    with torch.no_grad():\n",
    "        val_loss, val_bce, val_kld, accs = 0, 0, 0, 0\n",
    "        for x_batch, x_batch_unnormed, _, _ in valid_generator:\n",
    "            vae = vae.eval()\n",
    "\n",
    "            # Forward pass\n",
    "            dec_params, mu, logvar = vae(emb, x_batch.to(device))\n",
    "\n",
    "            #  sample from decoder posterior (binomial with support [0,1,2])\n",
    "            dec_dist = torch.distributions.binomial.Binomial(total_count=2, probs=dec_params)\n",
    "            out_sample = dec_dist.sample()\n",
    "\n",
    "            # Compute loss\n",
    "            crit_out = criterion(dec_params, x_batch_unnormed, mu, logvar)\n",
    "            val_loss += crit_out[0].item()\n",
    "            val_bce += crit_out[1].item()\n",
    "            val_kld += crit_out[2].item()\n",
    "            accs += (out_sample.cpu() == x_batch_unnormed).float().sum().item()\n",
    "\n",
    "        # Monitoring: Minibatch\n",
    "        print('[epoch {}] loss: {:.3f} bce: {:.3f} kld: {:.3f} acc: {:.3f}'.format(e, \n",
    "                                                                                   val_loss/len(valid_generator), \n",
    "                                                                                   val_bce/len(valid_generator), \n",
    "                                                                                   val_kld/len(valid_generator),\n",
    "                                                                                   accs/(out_sample.shape[0]*out_sample.shape[1]*len(valid_generator))))\n",
    "\n",
    "    print('completed epoch: {}/{}'.format(e, n_epochs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(klds, label='KL div')\n",
    "plt.plot(bces, label='recon loss')\n",
    "plt.plot(losses, label='loss')\n",
    "plt.legend(loc='upper right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_batch, test_batch_unnorm, label, _ = next(iter(valid_generator))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dec_params, mu, _ = vae(emb, test_batch.to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_batch_recon = torch.distributions.binomial.Binomial(total_count=2, probs=dec_params)\n",
    "out_sample = dec_dist.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_per_pos = (out_sample.cpu() == test_batch_unnorm).float().mean(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "worst_snp = acc_per_pos.argmin().item()\n",
    "print(test_batch_unnorm[:,worst_snp])\n",
    "print(out_sample[:,worst_snp])\n",
    "print(dec_params.mean(0)[worst_snp])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_dec_params = dec_params.mean(0).cpu().detach().numpy()\n",
    "plt.scatter(mean_dec_params, acc_per_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(mean_dec_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  TODO: compare learned decoder probability with allele frequency!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Make UMAP of latent dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See here for UMAP implementation: https://github.com/lmcinnes/umap\n",
    "import umap\n",
    "import seaborn as sns\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = umap.UMAP(n_neighbors=5,\n",
    "                      min_dist=0.3,\n",
    "                      metric='correlation').fit_transform(mu.cpu().detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  get label names\n",
    "exp_path = Path('/home/rochefortc/shared_disk_wd4tb/rochefortc/Dietnetwork/Dietnet2/1000G_EXP/EXP01_2020.07')\n",
    "exp_folder = 'REPRODUCE_2020.07'\n",
    "full_path = exp_path / exp_folder / '{}_fold{}'.format(exp_folder, which_fold)\n",
    "label_names = np.load(full_path / 'additional_data.npz')['label_names']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "superpop_mapping = {\"AFR\": {\"YRI\", \"LWK\", \"GWD\", \"MSL\", \"ESN\"},\n",
    "                    \"EUR\": {\"IBS\", \"TSI\", \"FIN\", \"GBR\", \"CEU\"},\n",
    "                    \"EAS\": {\"JPT\", \"KHV\", \"CHB\", \"CHS\", \"CDX\"},\n",
    "                    \"SAS\": {\"PJL\", \"BEB\", \"STU\", \"ITU\", \"GIH\"},\n",
    "                    \"AMR\": {\"ASW\", \"ACB\", \"PUR\", \"CLM\", \"PEL\", \"MXL\"}}\n",
    "\n",
    "inv_superpop_mapping = {}\n",
    "for key in superpop_mapping.keys():\n",
    "    for value in superpop_mapping[key]:\n",
    "        inv_superpop_mapping[value] = key\n",
    "\n",
    "labels_with_names = [inv_superpop_mapping[label_names[i]] for i in label]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_plot = pd.DataFrame({'umap0': embedding[:,0],\n",
    "                        'umap1': embedding[:,1],\n",
    "                        'label': pd.Categorical(values=label.numpy(), categories=range(26)),\n",
    "                        'superpop': pd.Categorical(values=labels_with_names, categories=superpop_mapping.keys())})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_context(\"talk\", font_scale=1.1)\n",
    "plt.figure(figsize=(10,6))\n",
    "sns.scatterplot(data=to_plot, x='umap0', y='umap1', hue='superpop')\n",
    "plt.xlabel(\"UMAP 1\")\n",
    "plt.ylabel(\"UMAP 2\")\n",
    "# place the legend outside the figure/plot\n",
    "plt.legend(bbox_to_anchor=(1.01, 1),borderaxespad=0)\n",
    "plt.title(\"UMAP of Sample\")\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare with UMAP on raw genotypes\n",
    "\n",
    "embedding_2 = umap.UMAP(n_neighbors=5,\n",
    "                        min_dist=0.3,\n",
    "                        metric='correlation').fit_transform(test_batch.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_plot = pd.DataFrame({'umap0': embedding_2[:,0],\n",
    "                        'umap1': embedding_2[:,1],\n",
    "                        'label': pd.Categorical(values=label.numpy(), categories=range(26)),\n",
    "                        'superpop': pd.Categorical(values=labels_with_names, categories=superpop_mapping.keys())})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_context(\"talk\", font_scale=1.1)\n",
    "plt.figure(figsize=(10,6))\n",
    "sns.scatterplot(data=to_plot, x='umap0', y='umap1', hue='superpop')\n",
    "plt.xlabel(\"UMAP 1\")\n",
    "plt.ylabel(\"UMAP 2\")\n",
    "# place the legend outside the figure/plot\n",
    "plt.legend(bbox_to_anchor=(1.01, 1),borderaxespad=0)\n",
    "plt.title(\"UMAP of Sample\")\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (dietnetwork)",
   "language": "python",
   "name": "dietnetwork"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
